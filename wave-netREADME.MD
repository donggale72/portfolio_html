1. 배경

본 논문은 오디오와 텍스트를 컨블루션 네트워크를 사용하여 결합확률로 새롭게 원시 오디오를 생성한다.
WaveNet이 인간의 목소리를 모방하여 현존하는 최고의 TTS(Text-to-Speech) 시스템보다 더 자연스럽게 들리는 음성을 생성할 수 있어
인간 성능과의 격차를 50% 이상 줄일 수 있음을 보여주었다.


2. 목적

일반적으로 음성 합성 또는 TTS(텍스트 음성 변환)라고 하는 프로세스와 컴퓨터를 사용하여 음성을 생성하는 것은 여전히 
단일 음성으로 된 TTS 에 기반을 두고 있다.<br>
이에 본 논문은 원시 오디오 생성에있어 시계열적 자기회귀를 처리하기 위해 확장된 인과 관계 컨불루션을 기반으로 하는 새로운 아키텍처를 개발 
하는것이 목적이다.

![](https://assets-global.website-files.com/621e749a546b7592125f38ed/62227b13d0dea8074a97b55c_unnamed.gif?raw=true)

3. 필요성

기존의 음성합성 TTS(텍스트 음성변환)는 단일음성에 기반하여서 새로운 음성을 생성하는데 한계가 있었다.<br>
이에 WaveNet이 이러한 문제를 해결하고자 하였으며, WaveNet이 오디오 생성(예: TTS, 음악, 음성 향상, 음성 변환, 소스 분리)에 의존하는
많은 응용 프로그램을 처리하느데 일반적이고 유연한 프레임워크를 제공해 준다고할 수 있다.


4. 실험설계

WaveNet의 조건부 확률 분포는 컨볼루션 레이어 스택으로 모델링하였으며, 네트워크에는 풀링 계층이 없으며 모델의 출력은 입력과 동일한 시간 차원을
갖도록 하였다.<br>
훈련 시간에 모든 시간 단계에 대한 조건부 예측은 ground truth x의 모든 시간 단계가 알려져 있기 때문에 병렬로 이루어져 있으며,
모델을 생성할 때 예측은 순차적으로 각 샘플이 예측된 후 네트워크에 피드백되어 다음 샘플을 예측하도록 하였다.

![](https://assets-global.website-files.com/621e749a546b7592125f38ed/62227b1d1dd26da452c9e160_unnamed-2.gif)

인과 관계 컨볼루션이 있는 모델은 매우 긴 시퀀스에 적용될 때 일반적으로 RNN보다 학습 속도가 더 빠르며, 인과관계 컨볼루션의 문제 중 하나는 
수용 필드를 증가시키기 위해서는 많은 레이어 또는 큰 필터가 필요하다. <br>
오디오 샘플에 대한 조건부 분포 모델링을 위해 softmax를 사용하였는데 그 이유는 범주형 분포가 유연하며 임의의 분포를 더 쉽게 모델링 할 수 있기 때문이다.<br>
원시 오디오는 일반적으로 16비트 정수 값의 시퀀스로 저장되기 때문에 소프트맥스 계층은 가능한 모든 값을 모델링하기 위해
시간 단계당 65,536개의 확률을 출력해야 하므로 이를 보다 쉽게 하기 위해 256개의 값으로 스케일링 했다.<br>
잔차와 매개변수는 건너뛰기로 네트워크 전체에 연결하였기에 수렴속도가 빠르며, 훨씬 깊은 모델의 교육을 가능하게 했다.<br>
네트워크에 input, output 차원이 동일하며, 최적화는 MLE를 사용한다. 
(다항분포 MLE -> minimize negative-log-likelihood -> minimize cross-entropy) 


5. 검증

WaveNet의 오디오 모델링 성능을 측정하기 위해 다중 화자 음성 생성(텍스트에 기반하지 않음), TTS 및 음악 오디오 모델링
의 세 가지 작업에서 평가했다.<br>
다중화자 음성생성에 있어 데이터 세트는 109명의 다른 화자들로부터 44시간 동안의 데이터로 구성되었다.<br>
두 번째 실험에서는 TTS를 적용했으며 동일한 단일 화자 음성 데이터베이스를 사용했으며, 북미 영어 데이터 세트에는 24.6시간 분량의 음성 데이터가,
중국어 데이터 세트에는 34.8시간이 사용되었다.<br>
음약은 약 200시간 분량의 음악 오디오로 구성된 MagnaTagATune 데이터 세트(Law & Von Ahn, 2009)를 사용하여 각 29초 클립에
장르, 악기, 템포, 볼륨 및 음악 분위기를 설명하는 188개 세트의 태그가 주석으로 추가되었으며, • YouTube 동영상
에서 가져온 약 60시간 분량의 피아노 솔로 음악으로 구성된 YouTube 피아노 데이터 세트도 추가되었다.<br> 
이러한 모델을 정량적으로 평가하기는 어렵지만 조화롭고 미학적이었다.<br>
WaveNet은 생성 모델로 설계되었지만 음성 인식과 같은 구별되는 오디오 작업에 간단하게 적용할 수도 있다. <br>
WaveNets를 사용하여 확장된 컨볼루션 레이어를 사용하면 LSTM 장치를 사용하는 것보다 훨씬 효과적이다.<br>
는 WaveNet을 두 개의 손실 항으로 훈련했으며. 하나는 다음 샘플을 예측하고 다른 하나는 프레임을 분류했다.<br>
델은 단일 손실보다 일반화되고 테스트 세트에서 18.8 PER을 달성했다


6. 결 론

본 논문에서는 음파 레벨에서 직접 작동하는 오디오 데이터의 심층 생성 모델인 WaveNet을 제시했다.<br>
WaveNet은 자기 회귀적이며 인과 필터를 확장된 회선과 결합하여 수용 필드가 깊이에 따라 기하급수적으로 증가하도록 하며, 이는 오디오 신호의 장
거리 시간 종속성을 모델링하는 데 중요하다. <br>
WaveNet이 글로벌(예: 화자 ID) 또는 로컬 방식(예: 언어 기능)의 다른 입력에 대해 어떻게 조정될 수 있는지 보여주었다.<br>
TTS에 적용했을 때 WaveNet은 주관적인 자연스러움에서 현재 최고의 TTS 시스템을 능가하는 샘플을 생성했으며, 마지막으
로 WaveNet은 음악 오디오 모델링 및 음성 인식에 적용했을 때 매우 휼륭한 결과를 보여주었다.
